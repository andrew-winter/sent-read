scrapes <- c("httr", "geniusr", "tidytext")
lapply(scrapes, require, character.only = TRUE)
baseURL <- "https://api.genius.com/search?q="
token <- "Z12YlAUALbWknjemUTrwHSnGkbbCpbprSqoVbt7yXhjz0sDX_v3pRnNPTq8k2Ldm"
bing <- get_sentiments("bing")
bing_positive_sent <- function(song) {
  song$sentiment[song$sentiment == "positive"] %>% length()}
bing_negative_sent <- function(song) {
  song$sentiment[song$sentiment == "negative"] %>% length() *-1}
song_length <- function(song) {song %>% bind_rows %>% nrow}

quick_albums <- function(search, artist = NULL) {
  genius_search <- search_song(search)
  genius_tibble <- lapply(genius_search$song_id, get_song_meta) %>% 
    bind_rows %>% as_tibble %>% select(song_name, artist_name, album_name,
    song_id, album_id, release_date) %>% 
      arrange(as.numeric(left(release_date, 4)),
              as.numeric(mid(release_date, 6, 2)))
  unique_ids <- unique(genius_tibble$album_id)
return(list(genius_tibble, unique_ids))
}

line_detect <- function(lyrics, str, just_one_album = FALSE) {
  if (just_one_album == FALSE) {
    result <- lapply(seq_along(lyrics), function(xalbum) {
      lapply(seq_along(lyrics[[xalbum]]), function(xsong) { 
        filter(lyrics[[xalbum]][[xsong]],
          str_detect(line, fixed(str, ignore_case = TRUE))
        ) %>% select(song_name, line)
      } ) %>% bind_rows(.id = "track")
    } ) %>% bind_rows(.id = "album")
  } else {
    result <- lapply(seq_along(lyrics), function(ysong) {
      filter(lyrics[[ysong]],
        str_detect(line, fixed(str, ignore_case = TRUE))
      ) %>% select(song_name, line)
    } ) %>% bind_rows(.id = "track")
  }
  return(result)
}

get_unsorted <- function(token, stop = stop_wordsB) {
  lapply(seq_along(token), function(q) {
    token[[q]] %>%
      lapply(anti_join, stop, "word") %>%
      lapply(anti_join, bing, "word") %>%
        bind_rows(.id = "song")
  } ) %>%
  bind_rows(.id = "album") %>%
    group_by(word) %>% count(sort = TRUE) %>% ungroup()
}

simple_sent <- function(album, token, join, ...) {
  result <- lapply(seq_along(album), function(q) {
    cbind.data.frame(album[[q]]$song_title,
      sapply(join[[q]], bing_positive_sent),
      sapply(join[[q]], bing_negative_sent),
      sapply(join[[q]], song_length),
      sapply(token[[q]], song_length)
    )
  } ) %>% bind_rows(.id = "album") %>% as_tibble()
  names(result) = c("album", "song", "pos", "neg", "slength", "tlength")
  return(result)
}


# tf-idf practice
# should tf-idf be done per album or per song? I'm thinking per song
# maybe there's not enough words per song to have this even make sense
# After looking at the fact that there's only three possible (should be four)
  # inverse document frequency values, think I will calculate per song
  # Another reason: Juice is ranked as the highest tf_idf, which in principle is
    # pretty weird. "Juice" is labelled as a particularly impactful word
    # because it has relatively high term frequency and a relatively high
    # inverse document frequency.
# "Juice" is impactful because it's a relatively high percentage of the words in 
  # "Acid Rap" and relatively infrequent in Chance's projects as a whole (in 1/3).
# Perhaps a better measure would be words that are in a relatively high 
  # percentage of a certain song, but relativelly infrequent in Chance's SONGS
  # as a whole.


library(janeaustenr)

freq_words <- austen_books() %>% unnest_tokens(word, text) %>%
  count(book, word, sort = TRUE)
# unnest_tokens(tbl, output, input, ...)
# unnest 'austen_books()' text by word, then count frequency of words per book
# Chance_tokens is assumed


Chance_counts <- lapply(1:4, function(x) {
  Chance_tokens[[x]] %>% bind_rows(.id = "song")
  } ) %>%
    bind_rows(.id = "album") %>% mutate(track = paste0(album, "-", song)) 
# Count words per album-- The Big Day has the most b/c it's the longest
Chance_freq <- Chance_counts %>% count(album, word, sort = TRUE)
Chance_freq <- Chance_freq %>%
  mutate(album = replace(album, album == "1", "10 Day")) %>%
  mutate(album = replace(album, album == "2", "Acid Rap")) %>% 
  mutate(album = replace(album, album == "3", "Coloring Book")) %>% 
  mutate(album = replace(album, album == "4", "The Big Day"))

# Count total words per album, and combine them
Chance_total_counts <- Chance_freq %>% group_by(album) %>%
  summarize(total = sum(n))
Chance_freq <- left_join(Chance_freq, Chance_total_counts, "album")
# For the final 'Chance_freq', just need a tibble of
  # documents, words, word counts, and word counts per document

per_album <- Chance_freq %>% bind_tf_idf(word, album, n) %>% arrange(desc(tf_idf))
# Before adding 10 Day, I thiiiink "juice" was still the biggest word
  # It's not, now (both top words are from 10 Day)
# Let's see how tf_idf changes when the documents used are songs not albums

Chance_freq_songs <- Chance_counts %>% select(track, song_name, word) %>%
  count(track, song_name, word, sort = TRUE)
Chance_song_counts <- Chance_freq_songs %>% group_by(song_name) %>% 
  summarize(total = sum(n))
Chance_freq_join <- left_join(Chance_freq_songs, Chance_song_counts, "song_name")
per_song <- Chance_freq_join %>% bind_tf_idf(word, song_name, n) %>%
  arrange(desc(tf_idf))

# If I feel like talking about Zipf's Law, which I don't and know nothing about
Chance_freq_song_rank <- Chance_freq_join %>% group_by(song_name) %>%
  mutate(rank = row_number(), term_freq = n/total)

a <- top_n(per_album, 100) %>% arrange(
b <- top_n(per_song, 100)
semi_join(a, b, "word")

anti_join(a, b, "word")
anti_join(b, a, "word")



brk_ids <- c(343250, 349160, 367722, 458278, 541256)
brk_albums <- lapply(brk_albums, scrape_tracklist)
brk_lyrics <- lapply(1:5, function(x) {
  brk_albums[[x]]$song_lyrics_url %>% scrape_lyrics_url } )

# Greta Van Fleet case study
  # 0) introduce
  # 1) scrape, tokenize
  # 2) assess common words, stop words, custom bing words (repeated step)
    # visualize: words contribute most to sentiment, overlooked words
  # 3) establish custom stop/bing words, set up as separate "joins" or "bings"
  # 4) use 'simple_sent()' to compare impact of word changes
    # visualize: difference between joins
  # 5) draw conclusions, check different sentiments

# scrape albums, lyrics, tokens
gvf_albums <- lapply(c(380196, 448142), scrape_tracklist)
gvf_lyrics <- lapply(1:2, function(album) {
  gvf_albums[[album]]$song_lyrics_url %>% lapply(scrape_lyrics_url) } )
gvf_tokens <- lapply(1:2, function(album) {
  gvf_lyrics[[album]] %>% lapply(unnest_tokens, word, line) } )


# Analyze stop words per song/album
gvf_stop_words <- lapply(1:2, function(album) {
  gvf_tokens[[album]] %>% lapply(inner_join, stop_words, "word") %>%
    bind_rows(.id = "song") } ) %>% bind_rows(.id = "album")
gvf_stop_words %>% group_by(word) %>% count(sort = TRUE)

# Look at words that don't sort into either stop_words or sentiment words
  # example: 'Age of Man' unsorted words
gvf_tokens[[2]][[1]] %>% anti_join(stop_words, "word") %>% anti_join(bing, "word")
gvf_unsorted <- lapply(1:2, function(album) { gvf_tokens[[album]] %>% 
                  lapply(anti_join, stop_words, "word") %>%
                  lapply(anti_join, bing, "word") %>% 
                    bind_rows(.id = "song")
                  } ) %>% bind_rows(.id = "album") %>% 
                      group_by(album, word) %>% count(sort = TRUE)

# Add/remove custom stop_words and custom bing words
# With (or without) custom words, set up custom joins (or use default orig_bing)
gvf_custom_stop <- tribble(~word, ~lexicon)
gvf_stop <- bind_rows(stop_words, gvf_custom_stop)
gvf_custom_words <- tribble(~word, ~sentiment, 
                            "heart", "positive", "lovin", "positive")
gvf_custom_bing <- bind_rows(bing, gvf_custom_words)

gvf_orig_join <- lapply(1:2, function(x) {
  gvf_tokens[[x]] %>% lapply(inner_join, bing, "word") } )
gvf_custom_join <- lapply(1:2, function(x) {
  gvf_tokens[[x]] %>% lapply(inner_join, gvf_custom_bing, "word") } )


simple_sent(gvf_albums, gvf_tokens, gvf_orig_join)$pos -
simple_sent(gvf_albums, gvf_tokens, gvf_custom_join)$pos




Cole_albums <- lapply(c(11280, 499569, 115138, 309072, 420709), scrape_tracklist)
Cole_lyrics <- lapply(1:5, function(x) { Cole_albums[[x]]$song_lyrics_url %>%
  lapply(scrape_lyrics_url) } )
Cole_tokens <- lapply(1:5, function(x) { Cole_lyrics[[x]] %>%
  lapply(unnest_tokens, word, line) } )

something <- lapply(1:5, function(x) {
  Cole_tokens[[x]] %>% lapply(inner_join, bing, "word") } )


simple_sent(Cole_albums, Cole_tokens, something)


# old one
line_detect <- function(lyrics, album = 1, str) {
  lapply(c(1:length(lyrics[[album]])), function(a) {
    filter(lyrics[[album]][[a]], str_detect(line, 
      fixed(str, ignore_case = TRUE) )) %>% 
    select(song_name, line)} ) %>% bind_rows(.id = "song")
}




Kanye_albums <- lapply(c(4342, 4352, 4339, 4345, 4343, 34024, 120604, 424304), 
  scrape_tracklist)
Kanye_lyrics <- lapply(1:8, function(x) { Kanye_albums[[x]]$song_lyrics_url %>%
  lapply(scrape_lyrics_url) } )
Kanye_tokens <- lapply(1:8, function(x) {
  Kanye_lyrics[[x]] %>% lapply(unnest_tokens, word, line) } )

lapply(1:8, function(x) {
  Kanye_tokens[[x]] %>% lapply(inner_join, stop_words, "word") } )

get_unsorted(Kanye_tokens)

line_detect(Kanye_lyrics, "baby")
line_detect(Kanye_lyrics, "life")
line_detect(Kanye_lyrics, "God")
line_detect(Kanye_lyrics, "money")













quick_sentiment <- function(...) {
  Tracklists <- lapply(list(...), scrape_tracklist)
  Lyrics <- list()
    for (album in 1:length(Tracklists)) {
      Lyrics[[album]] <- lapply(Tracklists[[album]]$song_lyrics_url,
      scrape_lyrics_url) }
  Tokens <- list()
    for (album in 1:length(Tracklists)) {
      Tokens[[album]] <- lapply(Lyrics[[album]], unnest_tokens, word, line)}
  SentList <- list()
    for (album in 1:length(Tokens)) {
      SentList[[album]] <- cbind.data.frame(
        Tracklists[[album]]$song_title,
        lapply(Tokens[[album]], inner_join, afinn, "word") %>%
          sapply(positive_sent),
        lapply(Tokens[[album]], inner_join, afinn, "word") %>%
          sapply(negative_sent),
        sapply(Tokens[[album]], song_length)
      )
    names(SentList[[album]]) <- c("song", "pos", "neg", "wlength")
    }
  Sent <- bind_rows(SentList, .id = "album") %>% as_tibble %>% 
    mutate(dif = pos + neg)
return(Sent)
}
# ^Rough-and-tumble 'quick_sentiment()' function--------------------------------
quick_sent_plot <- function(x, style = "SIMPLE") {
  x$album <- factor(x$album, levels = unique(as.character(x$album)))
  x$song <- factor(x$song, levels = unique(as.character(x$song)))
  plot <- ggplot(x, aes(x = song)) +
    geom_col(aes(y = pos, fill = album), color = "black", alpha = 0.6) + 
    geom_col(aes(y = neg), color = "black", alpha = 0.5) +
    labs(y = "negativity / positivity")
  if (style == "SIMPLE") {
    plot <- plot + theme(axis.title.x = element_blank(),
      axis.text.x = element_blank(),
      axis.ticks.x = element_blank(),
      legend.position = "none")
  } else {
    plot <- plot + theme(axis.text.x =
      element_text(angle = 90, hjust = 1), legend.position = "none")}
return(plot)
}
# ^Rough-and-tumble 'quick_sent_plot()' function--------------------------------
# Other functions specifically for lyric sentiment analysis---------------------
afinn_join <- function(song) {song %>% 
  anti_join(stop_words, by = "word") %>% 
    inner_join(afinn, by = "word")}
positive_sent <- function(song) {sum(song$value[song$value > 0])}
negative_sent <- function(song) {sum(song$value[song$value < 0])}
bing_positive_sent <- function(song) {
  song$sentiment[song$sentiment == "positive"] %>% length()}
bing_negative_sent <- function(song) {
  song$sentiment[song$sentiment == "negative"] %>% length() *-1}
song_length <- function(song) {song %>% bind_rows %>% nrow}






# Hamilton sent analysis, plots, etc--------------------------------------------
Hammeta <- search_song(search_term = "Hamilton")$song_id[[1]] %>% get_song_meta()
HamLyrics <- list()
HamLyrics <- lapply(scrape_tracklist(Hammeta$album_id)$song_lyrics_url,  
  scrape_lyrics_url)
HamTokens <- lapply(HamLyrics, unnest_tokens, word, line)
HamSent <- list()
for (song in 1:46) {
  HamSent[[song]] <- cbind.data.frame(
    HamTokens[[song]]$song_name[[1]],
    positive_sent(lapply(HamTokens, inner_join, afinn, by = "word")[[song]]),
    negative_sent(lapply(HamTokens, inner_join, afinn, by = "word")[[song]])
  )}
HamSentiment <- bind_rows(HamSent)
names(HamSentiment) <- c("song", "pos", "neg")
HamSentiment$song <- factor(HamSentiment$song, 
  levels = unique(as.character(HamSentiment$song)) %>% rev)
HamPlot <- ggplot(HamSentiment, aes(x = song)) +
  geom_col(aes(y = pos), linetype = 1, color = "black", alpha = 0.6, 
    fill = "sienna1") +
  geom_col(aes(y = neg), linetype = 1, color = "black", alpha = 0.6, 
    fill = "skyblue2") +
  coord_flip() + labs(title = "Lyrical Sentiment in Hamilton", x = "song",
    y = "sentiment by individual words")
print(HamPlot)


# Beatles sent analysis, plots, etc---------------------------------------------
BeatlesAlbums <- read.csv("BeatlesAlbums.csv", stringsAsFactors = FALSE) %>% 
  as_tibble()
# Wrote ugly code to get these album_ids; easier to preserve them then the code
BeatlesAlbum_ids <- c(27343, 29389, 27184, 21431, 22530, 12347, 17342, 11039, 
  12416, 16366, 29391, 12411, 29393)
BeatlesTracklists <- lapply(BeatlesAlbum_ids, scrape_tracklist)
BeatlesLyrics <- list()
for (album in 1:13) {
  BeatlesLyrics[[album]] <- lapply(BeatlesTracklists[[album]]$song_lyrics_url, 
    scrape_lyrics_url)}
BeatlesTokens <- list()
for (album in 1:13) {
  BeatlesTokens[[album]] <- lapply(BeatlesLyrics[[album]], 
    unnest_tokens, word, line)}
BeatlesSentA <- list() # afinn_join()
BeatlesSentB <- list() # inner_join(bing)
BeatlesSentC <- list() # inner_join(afinn)
for (album in 1:13) {
  BeatlesSentA[[album]] <- cbind.data.frame(
    BeatlesTracklists[[album]]$song_title,
    lapply(BeatlesTokens[[album]], afinn_join) %>% sapply(positive_sent),
    lapply(BeatlesTokens[[album]], afinn_join) %>% sapply(negative_sent),
    sapply(BeatlesTokens[[album]], song_length)
    )
  BeatlesSentB[[album]] <- cbind.data.frame(
    BeatlesTracklists[[album]]$song_title,
    lapply(BeatlesTokens[[album]], inner_join, bing, "word") %>%
      sapply(bing_positive_sent),
    lapply(BeatlesTokens[[album]], inner_join, bing, "word") %>%
      sapply(bing_negative_sent),
    sapply(BeatlesTokens[[album]], song_length)
    )
  BeatlesSentC[[album]] <- cbind.data.frame(
    BeatlesTracklists[[album]]$song_title,
    lapply(BeatlesTokens[[album]], inner_join, afinn, "word") %>%
      sapply(positive_sent),
    lapply(BeatlesTokens[[album]], inner_join, afinn, "word") %>%
      sapply(negative_sent),
    sapply(BeatlesTokens[[album]], song_length)
    )
  names(BeatlesSentA[[album]]) <- c("song", "pos", "neg", "wlength")
  names(BeatlesSentB[[album]]) <- c("song", "pos", "neg", "wlength")
  names(BeatlesSentC[[album]]) <- c("song", "pos", "neg", "wlength")
}
B <- bind_rows(BeatlesSentB, .id = "album") %>% as_tibble()
C <- bind_rows(BeatlesSentC, .id = "album") %>% as_tibble()
A <- bind_rows(BeatlesSentA, .id = "album") %>% as_tibble()
A <- A %>% mutate(dif = pos + neg)
BeatlesSimple <- bind_rows(A,B,C, .id = "method")
# Set to factors for ordering in ggplot
# Duplicate songs: "Yellow Submarine" and "All You Need Is Love"
A$song[[152]] <- "yellow submarine"
A$song[[157]] <- "all you need is love"
A$song <- factor(A$song, levels = unique(as.character(A$song)))
A$album <- factor(A$album, levels = unique(as.character(A$album)))
A2 <- A %>% mutate(pos2 = 
  abs( pos * (wlength-mean(wlength)/sd(wlength)) ), neg2 =
  -1 * abs( neg * (wlength-mean(wlength)/sd(wlength)) ) )

A3 <- A %>% mutate(pos3 = pos/wlength, neg3 = neg/wlength)
BeatlesPlotA <- ggplot(A, aes(x = song), linetype = 1) + 
  geom_col(aes(y = pos, fill = album), color = "black", alpha = 0.6) +
  geom_col(aes(y = neg), color = "black", alpha = 0.4) +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        legend.position = "none") +
  labs(title = "Half of What I Say is Meaningless", 
       subtitle = "Sentiment Analysis of The Beatles' Lyrics",
       y = "negativity / positivity")
BeatlesPlotA3 <- ggplot(A3, aes(x = song), linetype = 1) + 
  geom_col(aes(y = pos3, fill = album), color = "black", alpha = 0.6) +
  geom_col(aes(y = neg3), color = "black", alpha = 0.4) +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        legend.position = "none") +
  labs(title = "Half of What I Say is Meaningless", 
       subtitle = "Sentiment Analysis of The Beatles' Lyrics",
       y = "negativity / positivity")
print(BeatlesPlotA3)
BeatlesPlotA +
  annotate(geom = "text", x = 121, y = -30, angle = 90, size = 4,
    label = "All You Need Is Love") +
  annotate(geom = "text", x = 170, y = 40, angle = 90, size = 4,
    label = "I Want You (She's So Heavy)") +
  annotate(geom = "text", x = 160, y = -30, angle = 90, size = 3,
    label = "George Martin's songs on Yellow Submarine")

BeatlesLength <- ggplot(A, aes(x = album, y = wlength)) + geom_boxplot() +
  scale_x_discrete(labels = BeatlesAlbums$Title)
print(BeatlesLength)

